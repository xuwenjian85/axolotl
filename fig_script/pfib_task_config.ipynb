{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3909d0",
   "metadata": {},
   "source": [
    "**True Outliers**\n",
    "define have outliers AE defects 49, from S2 & S4.\n",
    "Supplemental Tables of paper [3]   \n",
    "(Table S2. Summary of cases diagnosed via RNA-seq,   \n",
    "Table S4. Summary of WES-diagnosed cases with an RNA-defect)  \n",
    "were manually merged. All aberrant expression events (labeled as ‘AE’ in the original publication) were extracted and used as 49 true outliers of the pfib dataset.\n",
    "\n",
    "note:  \n",
    "GeneCards Symbol: MICOS13  == C19orf70  \n",
    "GeneCards Symbol: IARS1 == IARS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8dd782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "import networkx as nx\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff6c80",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "/mnt/disk7t/xwj/axolotl_rev/pfib_423/fib_ns--hg19--gencode34\n",
    "├── [ 370]  DESCRIPTION.txt\n",
    "├── [6.3M]  geneCounts.tsv.gz\n",
    "├── [ 34M]  k_j_counts.tsv.gz\n",
    "├── [ 13M]  k_theta_counts.tsv.gz\n",
    "├── [ 32M]  n_psi3_counts.tsv.gz\n",
    "├── [ 32M]  n_psi5_counts.tsv.gz\n",
    "├── [ 46M]  n_theta_counts.tsv.gz\n",
    "└── [7.7K]  sample_annotation.tsv\n",
    "/mnt/disk7t/xwj/axolotl_rev/pfib_423/fib_ss--hg19--gencode34\n",
    "├── [ 482]  DESCRIPTION.txt\n",
    "├── [ 10M]  geneCounts.tsv.gz\n",
    "├── [ 61M]  k_j_counts.tsv.gz\n",
    "├── [ 25M]  k_theta_counts.tsv.gz\n",
    "├── [ 57M]  n_psi3_counts.tsv.gz\n",
    "├── [ 57M]  n_psi5_counts.tsv.gz\n",
    "├── [ 86M]  n_theta_counts.tsv.gz\n",
    "└── [ 13K]  sample_annotation.tsv\n",
    "\n",
    "\n",
    "'/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed/'\n",
    "df_true49.txt (outliers)\n",
    "/mnt/disk7t/xwj/axolotl_rev/pfib_423/gencode.v44lift37.basic.annotation.gtf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157598ff",
   "metadata": {},
   "source": [
    "## read known outliers and process counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4407160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Ensembl Gene ID  Gene Symbol             ensg\n",
      "ensg                                                               \n",
      "ENSG00000223972   ENSG00000223972.6_6      DDX11L1  ENSG00000223972\n",
      "ENSG00000227232   ENSG00000227232.5_5       WASH7P  ENSG00000227232\n",
      "ENSG00000243485  ENSG00000243485.5_11  MIR1302-2HG  ENSG00000243485\n",
      "ENSG00000237613   ENSG00000237613.2_6      FAM138A  ENSG00000237613\n",
      "ENSG00000268020   ENSG00000268020.3_5       OR4G4P  ENSG00000268020\n"
     ]
    }
   ],
   "source": [
    "gtf_file = \"/mnt/disk7t/xwj/axolotl_rev/pfib_423/gencode.v44lift37.basic.annotation.gtf\"\n",
    "# GTF 文件的格式是固定的，关注第 9 列，它包含了基因的注释信息\n",
    "annotations = []\n",
    "with open(gtf_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        if line.startswith(\"#\"):  # 跳过注释行\n",
    "            continue\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        if fields[2] == \"gene\":  # 只处理基因条目\n",
    "            attributes = fields[8].split(\";\")\n",
    "            gene_id = None\n",
    "            gene_name = None\n",
    "            for attr in attributes:\n",
    "                if \"gene_id\" in attr:\n",
    "                    gene_id = attr.split(\" \")[1].strip('\"')\n",
    "                elif \"gene_name\" in attr:\n",
    "                    gene_name = attr.split(\" \")[2].strip('\"')\n",
    "                else:\n",
    "                    continue\n",
    "            if gene_id and gene_name:\n",
    "                annotations.append((gene_id, gene_name))\n",
    "                # break  # 只需要前两个字段\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(annotations, columns=[\"Ensembl Gene ID\", \"Gene Symbol\"])\n",
    "df['ensg'] = df['Ensembl Gene ID'].str.split('.').str[0]\n",
    "gtf = df.drop_duplicates(subset= ['Gene Symbol', 'ensg'] )\n",
    "gtf.index = gtf['ensg']\n",
    "\n",
    "# 输出结果\n",
    "print(gtf.head())\n",
    "# 保存为 CSV 文件\n",
    "# df.to_csv(\"gene_id_to_symbol.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3a9b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Gene</th>\n",
       "      <th>RNAdefects</th>\n",
       "      <th>TableName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R80184</td>\n",
       "      <td>M</td>\n",
       "      <td>ALDH18A1</td>\n",
       "      <td>AE, MAE</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R60537</td>\n",
       "      <td>M</td>\n",
       "      <td>ATP6AP1</td>\n",
       "      <td>AE, Var</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R62943</td>\n",
       "      <td>F</td>\n",
       "      <td>MICOS13</td>\n",
       "      <td>AE, AS</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R96820</td>\n",
       "      <td>F</td>\n",
       "      <td>CLPP</td>\n",
       "      <td>AE, AS</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R77611</td>\n",
       "      <td>F</td>\n",
       "      <td>DLD</td>\n",
       "      <td>AE, MAE</td>\n",
       "      <td>S2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample Sex      Gene RNAdefects TableName\n",
       "0  R80184   M  ALDH18A1    AE, MAE        S2\n",
       "1  R60537   M   ATP6AP1    AE, Var        S2\n",
       "2  R62943   F   MICOS13     AE, AS        S2\n",
       "3  R96820   F      CLPP     AE, AS        S2\n",
       "4  R77611   F       DLD    AE, MAE        S2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workdir = '/mnt/disk7t/xwj/axolotl_rev/'\n",
    "\n",
    "datadir = '/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed/'\n",
    "# df_true49.txt (outliers)\n",
    "# 文献提供的异常基因label\n",
    "file = f'{datadir}/df_true49.txt'\n",
    "outlier = pd.read_csv(file, sep=\"\\t\", index_col=None)\n",
    "if False:\n",
    "    # Supplemental Table output\n",
    "    outlier.to_excel(f'{workdir}/result/table/s3_pfib_outlier49.xlsx', \n",
    "                              sheet_name='s3_pfib_outlier49',index=True)\n",
    "outlier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13107c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316649bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12369, 269) (49, 5) 25 True\n",
      "Fibroblast_Stranded/FBSS/min_reads=10 stable_ngene=12369 nsample=269\n",
      "(13411, 154) (49, 5) 24 True\n",
      "Fibroblast_NonStranded/FBNS/min_reads=10 stable_ngene=13411 nsample=154\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "use = 'split'\n",
    "\n",
    "tissue_name_mapping = pd.DataFrame({\n",
    "    'TISSUE_ID': ['FBSS','FBNS'],\n",
    "    'TISSUE_NAME': ['Fibroblast_Stranded','Fibroblast_NonStranded'],\n",
    "    'file' : ['/mnt/disk7t/xwj/axolotl_rev/pfib_423/fib_ss--hg19--gencode34/geneCounts.tsv.gz', \n",
    "             '/mnt/disk7t/xwj/axolotl_rev/pfib_423/fib_ns--hg19--gencode34/geneCounts.tsv.gz'],\n",
    "})\n",
    "tissues = pd.DataFrame(\n",
    "    index = tissue_name_mapping.index,\n",
    "    columns = ['TISSUE_ID','TISSUE_NAME','N_SAMPLE','N_GENE','CTS_FILE', 'OUTLIER_FILE',])\n",
    "\n",
    "# 各组织cts表达矩阵和outlier\n",
    "for idx, row in tissue_name_mapping.iterrows():\n",
    "    tissue_id, tissue_name = row['TISSUE_ID'],  row['TISSUE_NAME']\n",
    "    file = row['file']\n",
    "    # (1) cts: expression matrix\n",
    "    # sample_list = s_anno.query('group == @group').index.tolist()\n",
    "    # cts = cts_raw.loc[:, sample_list].copy()\n",
    "    cts_raw = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "    cts = cts_raw[cts_raw.any(axis=1)]  # 去除全0行\n",
    "    cts.index = cts.index.str.split('.').str[0]\n",
    "\n",
    "    cts = cts[ cts.index.isin(df[\"ensg\"]) ]\n",
    "    cts.index = gtf.loc[cts.index, 'Gene Symbol'] # 转换为基因名 \n",
    "\n",
    "    cts = cts.groupby(cts.index).sum() # 按照基因ID合并重复行\n",
    "    min_reads = 10\n",
    "    cts = cts[ (cts > min_reads).all(axis=1) ] # 过滤掉在所有样本中读数小于min_reads的基因\n",
    "    cts.index.name, cts.columns.name = 'Gene', 'Sample' # 设置行列名\n",
    "\n",
    "    print( cts.shape, outlier.shape, outlier[\"Sample\"].isin(cts.columns).sum(), outlier[\"Gene\"].isin(cts.index).all(),)\n",
    "    # (2) outlier: true outlier gene-sample pair in cts.    \n",
    "    # sample meta table\n",
    "    sample_list_interest = cts.columns.tolist()\n",
    "    outlier_use = outlier.query('Sample in @sample_list_interest').copy()\n",
    "\n",
    "    ctsfile = f'{datadir}/cts_{tissue_id}_s{cts.shape[1]}_g{cts.shape[0]}.tsv.gz'\n",
    "    cts.to_csv(ctsfile, sep='\\t')\n",
    "    # outliers: part1 + part2\n",
    "    outlierfile =f'{datadir}/outlier_{tissue_id}_sg{outlier_use.shape[0]}.tsv'\n",
    "    outlier_use.to_csv(outlierfile, sep='\\t')\n",
    "    \n",
    "    print(f'{tissue_name}/{tissue_id}/min_reads={min_reads} stable_ngene={cts.shape[0]} nsample={cts.shape[1]}')\n",
    "\n",
    "    # print(outlierfile,ctsfile)\n",
    "    tissues.loc[idx, :] = [ tissue_id, tissue_name, cts.shape[1], cts.shape[0],ctsfile, outlierfile]\n",
    "    \n",
    "tissues.to_csv(f'{datadir}/tissues_{use}.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61eb11db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 5), (2, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier.shape, tissues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b78ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TISSUE_ID</th>\n",
       "      <th>TISSUE_NAME</th>\n",
       "      <th>N_SAMPLE</th>\n",
       "      <th>N_GENE</th>\n",
       "      <th>CTS_FILE</th>\n",
       "      <th>OUTLIER_FILE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FBSS</td>\n",
       "      <td>Fibroblast_Stranded</td>\n",
       "      <td>269</td>\n",
       "      <td>12369</td>\n",
       "      <td>/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...</td>\n",
       "      <td>/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FBNS</td>\n",
       "      <td>Fibroblast_NonStranded</td>\n",
       "      <td>154</td>\n",
       "      <td>13411</td>\n",
       "      <td>/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...</td>\n",
       "      <td>/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TISSUE_ID             TISSUE_NAME N_SAMPLE N_GENE  \\\n",
       "0      FBSS     Fibroblast_Stranded      269  12369   \n",
       "1      FBNS  Fibroblast_NonStranded      154  13411   \n",
       "\n",
       "                                            CTS_FILE  \\\n",
       "0  /mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...   \n",
       "1  /mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...   \n",
       "\n",
       "                                        OUTLIER_FILE  \n",
       "0  /mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...  \n",
       "1  /mnt/disk7t/xwj/axolotl_rev/pfib_423_processed...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f16b89",
   "metadata": {},
   "source": [
    "## prepare folders and config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09564e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备结果目录和流程所需config文件\n",
    "workdir = '/mnt/disk7t/xwj/axolotl_rev/'\n",
    "\n",
    "# level 1\n",
    "output_path = f'{workdir}/result/dataset_pfib_423_split'\n",
    "# level 2\n",
    "samples_path = f'{output_path}/samples'\n",
    "task_config_path = f'{output_path}/task_config'\n",
    "task_output_path = f'{output_path}/task_output'\n",
    "metric_output_path = f'{output_path}/metric'\n",
    "\n",
    "# print(workdir, samples_path, task_config_path, task_output_path, metric_output_path)\n",
    "os.system(f'mkdir -p {samples_path} {task_config_path} {task_output_path} {metric_output_path}')\n",
    "# os.system(f'chmod --silent -R 777 {task_output_path}')?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5445fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare task config file.\n",
    "# task_config table have columns indicating output filenames of different methods\n",
    "\n",
    "for i, row in tissues.iterrows():\n",
    "    \n",
    "    t  = row.TISSUE_ID\n",
    "    tn = row.TISSUE_NAME\n",
    "    ns = row.N_SAMPLE\n",
    "    ng = row.N_GENE\n",
    "    ctsfile = row.CTS_FILE\n",
    "    outlierfile = row.OUTLIER_FILE\n",
    "\n",
    "    prefix = f't{i:02d}_{t}_s{ns}_g{ng}' # id, number of samples, number of genes.\n",
    "    \n",
    "    cols = ['Dname','cts','samples','MyMethod','OUTRIDER','ABEILLE','OUTSINGLE']\n",
    "    tasks = [0] # list of parallel tasks\n",
    "    task_config = pd.DataFrame(index=tasks, columns=cols)\n",
    "    task_config.index.name = 'task'\n",
    "\n",
    "    task = 0 # 默认是全部样本, 所以only one task for this tissue  \n",
    "    task_config.loc[task, 'Dname' ] = t\n",
    "    task_config.loc[task, 'cts' ] = ctsfile\n",
    "    task_config.loc[task, 'samples' ] = f'{samples_path}/{prefix}.txt'\n",
    "    # create filenames\n",
    "    task_config.loc[task, 'MyMethod'] = f'{task_output_path}/{prefix}/{task:03d}_mymethod.txt.gz'\n",
    "    task_config.loc[task, 'OUTRIDER'] = f'{task_output_path}/{prefix}/{task:03d}_outrider.txt.gz'\n",
    "    task_config.loc[task, 'OUTSINGLE'] = f'{task_output_path}/{prefix}/{task:03d}_outsingle.txt.gz'\n",
    "    task_config.loc[task, 'ABEILLE'] = f'{task_output_path}/{prefix}/{task:03d}_abeille.txt.gz'\n",
    "\n",
    "    # 0. create config & output folder of parallel tasks\n",
    "    task_config.to_csv(f'{task_config_path}/{prefix}.config',sep='\\t')\n",
    "    os.system(f'mkdir -p {task_output_path}/{prefix}')\n",
    "    \n",
    "    # 1. sample ids of parallel tasks\n",
    "    # 将task specific样本列表作为one row添加到DataFrame中. 默认task是全部样本\n",
    "    cts = pd.read_csv(ctsfile, sep='\\t',index_col=0)\n",
    "    all_samples_df = pd.DataFrame(data=cts.columns.T.tolist()).transpose()\n",
    "    all_samples_df.index = task_config.index\n",
    "    all_samples_df.to_csv(f'{samples_path}/{prefix}.txt',sep='\\t')\n",
    "    \n",
    "    # 2. true outliers for parallel tasks. No down-sampling, this file is used by a set of tasks.\n",
    "    outlier = pd.read_csv(outlierfile, sep='\\t', index_col=0)\n",
    "    # 默认task是全部样本\n",
    "    outlier.to_csv(f'{samples_path}/{prefix}_outliers.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ff5a7",
   "metadata": {},
   "source": [
    "## subset to small sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0df1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 FBSS Fibroblast_Stranded (12369, 269) 269\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t00_FBSS_s269_g12369_sampled_configs_dict.pkl\n",
      "1 FBNS Fibroblast_NonStranded (13411, 154) 154\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t01_FBNS_s154_g13411_sampled_configs_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# 对ns和 ss 分别抽样\n",
    "# 定义样本量列表和随机种子\n",
    "sample_sizes = [100, 60, 30, 10]\n",
    "n_replicates = 10  # 每个样本量重复10次\n",
    "random_seeds = range(n_replicates)  # 使用0-9作为随机种子\n",
    "\n",
    "# 从tissues中获取信息\n",
    "for i, tissue_data in tissues.iterrows():\n",
    "    # tissue_data = tissues.iloc[0]\n",
    "    t = tissue_data['TISSUE_ID']  # TISSUE_ID\n",
    "    tn = tissue_data['TISSUE_NAME']  # TISSUE_NAME\n",
    "    ns = tissue_data['N_SAMPLE']  # N_SAMPLE\n",
    "    ng = tissue_data['N_GENE']  # N_GENE\n",
    "    ctsfile = tissue_data['CTS_FILE']  # CTS_FILE\n",
    "    outlierfile = tissue_data['OUTLIER_FILE']  # OUTLIER_FILE\n",
    "\n",
    "    # 创建基础前缀\n",
    "    base_prefix = f't{i:02d}_{t}_s{ns}_g{ng}' # id, number of samples, number of genes.\n",
    "    \n",
    "    cts = pd.read_csv(ctsfile, sep='\\t', index_col=0)\n",
    "    all_samples = cts.columns.tolist()\n",
    "    print(i, t, tn, cts.shape, len(all_samples))\n",
    "    \n",
    "    # positive samples\n",
    "    outlier = pd.read_csv(outlierfile, sep='\\t', index_col=0)\n",
    "    assert outlier['Sample'].size == len(set(outlier['Sample']))\n",
    "    postive_samples = outlier['Sample']\n",
    "    \n",
    "    # all negative samples\n",
    "    negative_samples = list(set(all_samples) - set(postive_samples) )\n",
    "    \n",
    "    # 创建字典存储所有抽样结果\n",
    "    sampled_configs = {}\n",
    "\n",
    "    # 对每个样本量进行抽样\n",
    "    for size in sample_sizes:\n",
    "        # 存储当前样本量的所有抽样结果\n",
    "        size_configs = {}\n",
    "        \n",
    "        for seed in random_seeds:\n",
    "            if size <= len(postive_samples):\n",
    "                part1_sampled = postive_samples.sample(n = size, random_state=seed).tolist()\n",
    "                n_negative = 0\n",
    "                negative_selected = []  \n",
    "            else:\n",
    "                part1_sampled = postive_samples.tolist()\n",
    "                n_negative = size - len(part1_sampled)\n",
    "                # 从阴性样本中随机抽样（数量 = 总样本量 - 阳性样本数量\n",
    "                # negative_selected =  np.random.choice(negative_samples, size=n_negative, replace=False)\n",
    "                negative_selected = pd.Series(negative_samples).sample(n = n_negative, random_state=seed).tolist() #, size=n_negative, replace=False)\n",
    "\n",
    "            # 合并阳性样本和随机选择的阴性样本\n",
    "            selected_samples =  part1_sampled +  negative_selected\n",
    "            assert len(selected_samples) == len(set(selected_samples))\n",
    "            # print(i,t, size, seed, len(selected_samples),  len(part1_sampled), part1_sampled[:3], n_negative, negative_selected[:3], )\n",
    "            \n",
    "            # 创建前缀\n",
    "            prefix = f'{base_prefix}_size{size}_seed{seed}'\n",
    "            \n",
    "            # 创建输出目录\n",
    "            output_dir = os.path.join(task_output_path, prefix)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # 创建样本列表文件\n",
    "            samples_file = os.path.join(samples_path, f'{prefix}.txt')\n",
    "            samples = pd.DataFrame(selected_samples).transpose()\n",
    "            samples.index.name = 'task'\n",
    "            samples.to_csv(samples_file, sep='\\t', header=True)\n",
    "            \n",
    "            # 创建config文件\n",
    "            cols = ['Dname', 'cts', 'samples', 'MyMethod', 'OUTRIDER', 'ABEILLE', 'OUTSINGLE']\n",
    "            task_config = pd.DataFrame(columns=cols)\n",
    "            task_config.index.name = 'task'\n",
    "            # 填充config数据\n",
    "            task = 0\n",
    "            task_config.loc[0, 'Dname'] = t\n",
    "            task_config.loc[0, 'cts'] = ctsfile\n",
    "            task_config.loc[0, 'samples'] = samples_file\n",
    "            task_config.loc[0, 'MyMethod'] = os.path.join(output_dir, f'{task:03d}_mymethod.txt.gz')\n",
    "            task_config.loc[0, 'OUTRIDER'] = os.path.join(output_dir, f'{task:03d}_outrider.txt.gz')\n",
    "            task_config.loc[0, 'OUTSINGLE'] = os.path.join(output_dir, f'{task:03d}_outsingle.txt.gz')\n",
    "            task_config.loc[0, 'ABEILLE'] = os.path.join(output_dir, f'{task:03d}_abeille.txt.gz')\n",
    "            # {prefix}/{task:03d}\n",
    "            \n",
    "            # 保存config文件\n",
    "            config_file = os.path.join(task_config_path, f'{prefix}.config')\n",
    "            task_config.to_csv(config_file, sep='\\t', index=False)\n",
    "            \n",
    "            # 存储结果\n",
    "            size_configs[f'seed_{seed}'] = {\n",
    "                'config': task_config,\n",
    "                'selected_samples': selected_samples,\n",
    "                'output_dir': output_dir\n",
    "            }\n",
    "        \n",
    "        # 将当前样本量的所有结果存入总字典\n",
    "        sampled_configs[f'size_{size}'] = size_configs\n",
    "\n",
    "    # sampled_configs现在包含了所有抽样结果和对应的配置文件\n",
    "    # 结构为：{sample_size: {seed: {'config': df, 'selected_samples': list, 'output_dir': str}}, ...}\n",
    "    output_file = os.path.join(task_config_path, f'{base_prefix}_sampled_configs_dict.pkl')\n",
    "    # 保存sampled_configs字典\n",
    "    import pickle\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(sampled_configs, f)\n",
    "\n",
    "    print(f\"sampled_configs已保存到: {output_file}\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a211dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 FBSS Fibroblast_Stranded (12369, 269) 269\n",
      "t00_FBSS_s269_g12369_pct0.04\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t00_FBSS_s269_g12369_pct0.04_sampled_configs_dict.pkl\n",
      "t00_FBSS_s269_g12369_pct0.08\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t00_FBSS_s269_g12369_pct0.08_sampled_configs_dict.pkl\n",
      "t00_FBSS_s269_g12369_pct0.16\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t00_FBSS_s269_g12369_pct0.16_sampled_configs_dict.pkl\n",
      "t00_FBSS_s269_g12369_pct0.24\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t00_FBSS_s269_g12369_pct0.24_sampled_configs_dict.pkl\n",
      "1 FBNS Fibroblast_NonStranded (13411, 154) 154\n",
      "t01_FBNS_s154_g13411_pct0.04\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t01_FBNS_s154_g13411_pct0.04_sampled_configs_dict.pkl\n",
      "t01_FBNS_s154_g13411_pct0.08\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t01_FBNS_s154_g13411_pct0.08_sampled_configs_dict.pkl\n",
      "t01_FBNS_s154_g13411_pct0.16\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t01_FBNS_s154_g13411_pct0.16_sampled_configs_dict.pkl\n",
      "t01_FBNS_s154_g13411_pct0.24\n",
      "sampled_configs已保存到: /mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_config/t01_FBNS_s154_g13411_pct0.24_sampled_configs_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "# 定义样本量列表和随机种子\n",
    "list_outlier_pct = [ 0.04, 0.08, 0.16, 0.24,]\n",
    "sample_sizes = [100,]\n",
    "\n",
    "n_replicates = 10  # 每个样本量重复10次\n",
    "random_seeds = range(n_replicates)  # 使用0-9作为随机种子\n",
    "\n",
    "# 从tissues中获取信息\n",
    "for i, tissue_data in tissues.iterrows():\n",
    "    # tissue_data = tissues.iloc[0]\n",
    "    t = tissue_data['TISSUE_ID']  # TISSUE_ID\n",
    "    tn = tissue_data['TISSUE_NAME']  # TISSUE_NAME\n",
    "    ns = tissue_data['N_SAMPLE']  # N_SAMPLE\n",
    "    ng = tissue_data['N_GENE']  # N_GENE\n",
    "    ctsfile = tissue_data['CTS_FILE']  # CTS_FILE\n",
    "    outlierfile = tissue_data['OUTLIER_FILE']  # OUTLIER_FILE\n",
    "    \n",
    "    cts = pd.read_csv(ctsfile, sep='\\t', index_col=0)\n",
    "    all_samples = cts.columns.tolist()\n",
    "    print(i, t, tn, cts.shape, len(all_samples))\n",
    "    \n",
    "    # positive samples\n",
    "    outlier = pd.read_csv(outlierfile, sep='\\t', index_col=0)\n",
    "    assert outlier['Sample'].size == len(set(outlier['Sample']))\n",
    "    postive_samples = outlier['Sample']\n",
    "    \n",
    "    # all negative samples\n",
    "    negative_samples = list(set(all_samples) - set(postive_samples) )\n",
    "    \n",
    "    for pct in list_outlier_pct: # 增加pct的变化\n",
    "        # 创建基础前缀\n",
    "        base_prefix = f't{i:02d}_{t}_s{ns}_g{ng}_pct{pct:.2f}'\n",
    "        print(base_prefix)\n",
    "        # 创建字典存储所有抽样结果\n",
    "        sampled_configs = {}\n",
    "        # 对每个样本量进行抽样\n",
    "        for size in sample_sizes:\n",
    "            # 存储当前样本量的所有抽样结果\n",
    "            size_configs = {}\n",
    "            n_positive = int(size * pct)\n",
    "            \n",
    "            for seed in random_seeds:\n",
    "                part1_sampled = postive_samples.sample(n = n_positive, random_state=seed*1000+n_positive).tolist()\n",
    "                n_negative = size - len(part1_sampled)\n",
    "                # 从阴性样本中随机抽样（数量 = 总样本量 - 阳性样本数量\n",
    "                # negative_selected =  np.random.choice(negative_samples, size=n_negative, replace=False)\n",
    "                negative_selected = pd.Series(negative_samples).sample(n = n_negative, random_state=seed*2000+n_negative).tolist() #, size=n_negative, replace=False)\n",
    "\n",
    "                # 合并阳性样本和随机选择的阴性样本\n",
    "                selected_samples =  part1_sampled +  negative_selected\n",
    "                assert len(selected_samples) == len(set(selected_samples))\n",
    "                # print(i,t, size, pct, seed, len(selected_samples),  len(part1_sampled), part1_sampled[:3], n_negative, negative_selected[:3], )\n",
    "                \n",
    "                # 创建前缀 + size + pct + seed\n",
    "                prefix = f'{base_prefix}_size{size}_seed{seed}'\n",
    "                \n",
    "                # 创建输出目录\n",
    "                output_dir = os.path.join(task_output_path, prefix)\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                # 创建样本列表文件\n",
    "                samples_file = os.path.join(samples_path, f'{prefix}.txt')\n",
    "                samples = pd.DataFrame(selected_samples).transpose()\n",
    "                samples.index.name = 'task'\n",
    "                samples.to_csv(samples_file, sep='\\t', header=True)\n",
    "                \n",
    "                # 创建config文件\n",
    "                cols = ['Dname', 'cts', 'samples', 'MyMethod', 'OUTRIDER', 'ABEILLE', 'OUTSINGLE']\n",
    "                task_config = pd.DataFrame(columns=cols)\n",
    "                task_config.index.name = 'task'\n",
    "                # 填充config数据\n",
    "                task = 0\n",
    "                task_config.loc[0, 'Dname'] = t\n",
    "                task_config.loc[0, 'cts'] = ctsfile\n",
    "                task_config.loc[0, 'samples'] = samples_file\n",
    "                task_config.loc[0, 'MyMethod'] = os.path.join(output_dir, f'{task:03d}_mymethod.txt.gz')\n",
    "                task_config.loc[0, 'OUTRIDER'] = os.path.join(output_dir, f'{task:03d}_outrider.txt.gz')\n",
    "                task_config.loc[0, 'OUTSINGLE'] = os.path.join(output_dir, f'{task:03d}_outsingle.txt.gz')\n",
    "                task_config.loc[0, 'ABEILLE'] = os.path.join(output_dir, f'{task:03d}_abeille.txt.gz')\n",
    "                # {prefix}/{task:03d}\n",
    "                \n",
    "                # 保存config文件\n",
    "                config_file = os.path.join(task_config_path, f'{prefix}.config')\n",
    "                task_config.to_csv(config_file, sep='\\t', index=False)\n",
    "                \n",
    "                # 存储结果\n",
    "                size_configs[f'seed_{seed}'] = {\n",
    "                    'config': task_config,\n",
    "                    'selected_samples': selected_samples,\n",
    "                    'output_dir': output_dir\n",
    "                }\n",
    "            \n",
    "            # 将当前样本量的所有结果存入总字典\n",
    "            sampled_configs[f'size_{size}'] = size_configs\n",
    "\n",
    "        # sampled_configs现在包含了所有抽样结果和对应的配置文件\n",
    "        # 结构为：{sample_size: {seed: {'config': df, 'selected_samples': list, 'output_dir': str}}, ...}\n",
    "        output_file = os.path.join(task_config_path, f'{base_prefix}_sampled_configs_dict.pkl')\n",
    "        # 保存sampled_configs字典\n",
    "        import pickle\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(sampled_configs, f)\n",
    "\n",
    "        print(f\"sampled_configs已保存到: {output_file}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_outlier_pct = [ 0.04, 0.08, 0.16, 0.24, 0.32, 0.40 ]\n",
    "sample_sizes = [50,]\n",
    "\n",
    "n_replicates = 10  # 每个样本量重复10次\n",
    "random_seeds = range(n_replicates)  # 使用0-9作为随机种子\n",
    "\n",
    "# 从tissues中获取信息\n",
    "for i, tissue_data in tissues.iterrows():\n",
    "    # tissue_data = tissues.iloc[0]\n",
    "    t = tissue_data['TISSUE_ID']  # TISSUE_ID\n",
    "    tn = tissue_data['TISSUE_NAME']  # TISSUE_NAME\n",
    "    ns = tissue_data['N_SAMPLE']  # N_SAMPLE\n",
    "    ng = tissue_data['N_GENE']  # N_GENE\n",
    "    ctsfile = tissue_data['CTS_FILE']  # CTS_FILE\n",
    "    outlierfile = tissue_data['OUTLIER_FILE']  # OUTLIER_FILE\n",
    "    \n",
    "    cts = pd.read_csv(ctsfile, sep='\\t', index_col=0)\n",
    "    all_samples = cts.columns.tolist()\n",
    "    print(i, t, tn, cts.shape, len(all_samples))\n",
    "    \n",
    "    # positive samples\n",
    "    outlier = pd.read_csv(outlierfile, sep='\\t', index_col=0)\n",
    "    assert outlier['Sample'].size == len(set(outlier['Sample']))\n",
    "    postive_samples = outlier['Sample']\n",
    "    \n",
    "    # all negative samples\n",
    "    negative_samples = list(set(all_samples) - set(postive_samples) )\n",
    "    \n",
    "    for pct in list_outlier_pct: # 增加pct的变化\n",
    "        # 创建基础前缀\n",
    "        base_prefix = f't{i:02d}_{t}_s{ns}_g{ng}_pct{pct:.2f}'\n",
    "        print(base_prefix)\n",
    "        # 创建字典存储所有抽样结果\n",
    "        sampled_configs = {}\n",
    "        # 对每个样本量进行抽样\n",
    "        for size in sample_sizes:\n",
    "            # 存储当前样本量的所有抽样结果\n",
    "            size_configs = {}\n",
    "            n_positive = int(size * pct)\n",
    "            \n",
    "            for seed in random_seeds:\n",
    "                part1_sampled = postive_samples.sample(n = n_positive, random_state=seed*1000+n_positive).tolist()\n",
    "                n_negative = size - len(part1_sampled)\n",
    "                # 从阴性样本中随机抽样（数量 = 总样本量 - 阳性样本数量\n",
    "                # negative_selected =  np.random.choice(negative_samples, size=n_negative, replace=False)\n",
    "                negative_selected = pd.Series(negative_samples).sample(n = n_negative, random_state=seed*2000+n_negative).tolist() #, size=n_negative, replace=False)\n",
    "\n",
    "                # 合并阳性样本和随机选择的阴性样本\n",
    "                selected_samples =  part1_sampled +  negative_selected\n",
    "                assert len(selected_samples) == len(set(selected_samples))\n",
    "                # print(i,t, size, pct, seed, len(selected_samples),  len(part1_sampled), part1_sampled[:3], n_negative, negative_selected[:3], )\n",
    "                \n",
    "                # 创建前缀 + size + pct + seed\n",
    "                prefix = f'{base_prefix}_size{size}_seed{seed}'\n",
    "                \n",
    "                # 创建输出目录\n",
    "                output_dir = os.path.join(task_output_path, prefix)\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                \n",
    "                # 创建样本列表文件\n",
    "                samples_file = os.path.join(samples_path, f'{prefix}.txt')\n",
    "                samples = pd.DataFrame(selected_samples).transpose()\n",
    "                samples.index.name = 'task'\n",
    "                samples.to_csv(samples_file, sep='\\t', header=True)\n",
    "                \n",
    "                # 创建config文件\n",
    "                cols = ['Dname', 'cts', 'samples', 'MyMethod', 'OUTRIDER', 'ABEILLE', 'OUTSINGLE']\n",
    "                task_config = pd.DataFrame(columns=cols)\n",
    "                task_config.index.name = 'task'\n",
    "                # 填充config数据\n",
    "                task = 0\n",
    "                task_config.loc[0, 'Dname'] = t\n",
    "                task_config.loc[0, 'cts'] = ctsfile\n",
    "                task_config.loc[0, 'samples'] = samples_file\n",
    "                task_config.loc[0, 'MyMethod'] = os.path.join(output_dir, f'{task:03d}_mymethod.txt.gz')\n",
    "                task_config.loc[0, 'OUTRIDER'] = os.path.join(output_dir, f'{task:03d}_outrider.txt.gz')\n",
    "                task_config.loc[0, 'OUTSINGLE'] = os.path.join(output_dir, f'{task:03d}_outsingle.txt.gz')\n",
    "                task_config.loc[0, 'ABEILLE'] = os.path.join(output_dir, f'{task:03d}_abeille.txt.gz')\n",
    "                # {prefix}/{task:03d}\n",
    "                \n",
    "                # 保存config文件\n",
    "                config_file = os.path.join(task_config_path, f'{prefix}.config')\n",
    "                task_config.to_csv(config_file, sep='\\t', index=False)\n",
    "                \n",
    "                # 存储结果\n",
    "                size_configs[f'seed_{seed}'] = {\n",
    "                    'config': task_config,\n",
    "                    'selected_samples': selected_samples,\n",
    "                    'output_dir': output_dir\n",
    "                }\n",
    "            \n",
    "            # 将当前样本量的所有结果存入总字典\n",
    "            sampled_configs[f'size_{size}'] = size_configs\n",
    "\n",
    "        # sampled_configs现在包含了所有抽样结果和对应的配置文件\n",
    "        # 结构为：{sample_size: {seed: {'config': df, 'selected_samples': list, 'output_dir': str}}, ...}\n",
    "        output_file = os.path.join(task_config_path, f'{base_prefix}_sampled_configs_dict.pkl')\n",
    "        # 保存sampled_configs字典\n",
    "        import pickle\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(sampled_configs, f)\n",
    "\n",
    "        print(f\"sampled_configs已保存到: {output_file}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1124fd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['FBNS',\n",
       "        '/mnt/disk7t/xwj/axolotl_rev/pfib_423_processed//cts_FBNS_s154_g13411.tsv.gz',\n",
       "        '/mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/samples/t01_FBNS_s154_g13411_pct0.24_size100_seed1.txt',\n",
       "        '/mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_output/t01_FBNS_s154_g13411_pct0.24_size100_seed1/000_mymethod.txt.gz',\n",
       "        '/mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_output/t01_FBNS_s154_g13411_pct0.24_size100_seed1/000_outrider.txt.gz',\n",
       "        '/mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_output/t01_FBNS_s154_g13411_pct0.24_size100_seed1/000_abeille.txt.gz',\n",
       "        '/mnt/disk7t/xwj/axolotl_rev//result/dataset_pfib_423_split/task_output/t01_FBNS_s154_g13411_pct0.24_size100_seed1/000_outsingle.txt.gz']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_configs['size_100']['seed_1']['config'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.12]",
   "language": "python",
   "name": "conda-env-py3.12-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
