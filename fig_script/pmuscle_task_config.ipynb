{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c05867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-08\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from datetime import date\n",
    "print(date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924dc691",
   "metadata": {},
   "source": [
    "\n",
    "```bash\n",
    "pmuscle_36_processed/\n",
    "├── [953K]  cts_M_s36_g13573.tsv.gz\n",
    "├── [ 700]  outlier_M_sg22.tsv\n",
    "└── [ 224]  tissues_pmuscle36.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a6ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcedir = '/mnt/disk7t/xwj/axolotl_rev/pmuscle_36/'\n",
    "datadir = '/mnt/disk7t/xwj/axolotl_rev/pmuscle_36_processed/'\n",
    "os.chdir(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13573, 36), (22, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier = pd.read_csv(f'{datadir}/outlier_M_sg22.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "min_reads = 10\n",
    "cts = pd.read_csv(f'{datadir}/cts_M_s36_g13573.tsv.gz', sep='\\t', index_col=0)\n",
    "cts.shape, outlier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13573, 36) (22, 3) 22 True\n",
      "muscle/M/min_reads=10 stable_ngene=13573 nsample=36\n"
     ]
    }
   ],
   "source": [
    "use = 'pmuscle36'\n",
    "tissue_name_mapping = pd.DataFrame({\n",
    "    'TISSUE_ID': ['M'],\n",
    "    'TISSUE_NAME': ['muscle',]\n",
    "})\n",
    "tissues = pd.DataFrame(\n",
    "    index = tissue_name_mapping.index,\n",
    "    columns = ['TISSUE_ID','TISSUE_NAME','N_SAMPLE','N_GENE','CTS_FILE', 'OUTLIER_FILE',])\n",
    "\n",
    "# 各组织cts表达矩阵和outlier\n",
    "for idx, row in tissue_name_mapping.iterrows():\n",
    "    tissue_id, tissue_name = row['TISSUE_ID'],  row['TISSUE_NAME']\n",
    "    # (1) cts: expression matrix\n",
    "    print( cts.shape, outlier.shape, outlier[\"Sample\"].isin(cts.columns).sum(), outlier[\"Gene\"].isin(cts.index).all(),)\n",
    "    # (2) outlier: true outlier gene-sample pair in cts.    \n",
    "    # sample meta table\n",
    "    sample_list_interest = cts.columns.tolist()\n",
    "    outlier_use = outlier.query('Sample in @sample_list_interest').copy()\n",
    "\n",
    "    ctsfile = f'{datadir}/cts_{tissue_id}_s{cts.shape[1]}_g{cts.shape[0]}.tsv.gz'\n",
    "    cts.to_csv(ctsfile, sep='\\t')\n",
    "    # outliers: part1 + part2\n",
    "    outlierfile =f'{datadir}/outlier_{tissue_id}_sg{outlier_use.shape[0]}.tsv'\n",
    "    outlier_use.to_csv(outlierfile, sep='\\t')\n",
    "    \n",
    "    print(f'{tissue_name}/{tissue_id}/min_reads={min_reads} stable_ngene={cts.shape[0]} nsample={cts.shape[1]}')\n",
    "\n",
    "    # print(outlierfile,ctsfile)\n",
    "    tissues.loc[idx, :] = [ tissue_id, tissue_name, cts.shape[1], cts.shape[0],ctsfile, outlierfile]\n",
    "    \n",
    "tissues.to_csv(f'{datadir}/tissues_{use}.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65223ee2",
   "metadata": {},
   "source": [
    "## prepare folders and config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备结果目录和流程所需config文件\n",
    "workdir = '/mnt/disk7t/xwj/axolotl_rev/'\n",
    "\n",
    "# level 1\n",
    "output_path = f'{workdir}/result/dataset_pmuscle_36'\n",
    "# level 2\n",
    "samples_path = f'{output_path}/samples'\n",
    "task_config_path = f'{output_path}/task_config'\n",
    "task_output_path = f'{output_path}/task_output'\n",
    "metric_output_path = f'{output_path}/metric'\n",
    "\n",
    "# print(workdir, samples_path, task_config_path, task_output_path, metric_output_path)\n",
    "os.system(f'mkdir -p {samples_path} {task_config_path} {task_output_path} {metric_output_path}')\n",
    "# os.system(f'chmod --silent -R 777 {task_output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare task config file.\n",
    "# task_config table have columns indicating output filenames of different methods\n",
    "for i, row in tissues.iterrows():\n",
    "    \n",
    "    t  = row.TISSUE_ID\n",
    "    tn = row.TISSUE_NAME\n",
    "    ns = row.N_SAMPLE\n",
    "    ng = row.N_GENE\n",
    "    ctsfile = row.CTS_FILE\n",
    "    outlierfile = row.OUTLIER_FILE\n",
    "\n",
    "    prefix = f't{i:02d}_{t}_s{ns}_g{ng}' # id, number of samples, number of genes.\n",
    "    \n",
    "    cols = ['Dname','cts','samples','MyMethod','OUTRIDER','ABEILLE','OUTSINGLE']\n",
    "    tasks = [0] # list of parallel tasks\n",
    "    task_config = pd.DataFrame(index=tasks, columns=cols)\n",
    "    task_config.index.name = 'task'\n",
    "\n",
    "    task = 0 # 默认是全部样本, 所以only one task for this tissue  \n",
    "    task_config.loc[task, 'Dname' ] = t\n",
    "    task_config.loc[task, 'cts' ] = ctsfile\n",
    "    task_config.loc[task, 'samples' ] = f'{samples_path}/{prefix}.txt'\n",
    "    # create filenames\n",
    "    task_config.loc[task, 'MyMethod'] = f'{task_output_path}/{prefix}/{task:03d}_mymethod.txt.gz'\n",
    "    task_config.loc[task, 'OUTRIDER'] = f'{task_output_path}/{prefix}/{task:03d}_outrider.txt.gz'\n",
    "    task_config.loc[task, 'OUTSINGLE'] = f'{task_output_path}/{prefix}/{task:03d}_outsingle.txt.gz'\n",
    "    task_config.loc[task, 'ABEILLE'] = f'{task_output_path}/{prefix}/{task:03d}_abeille.txt.gz'\n",
    "\n",
    "    # 0. create config & output folder of parallel tasks\n",
    "    task_config.to_csv(f'{task_config_path}/{prefix}.config',sep='\\t')\n",
    "    os.system(f'mkdir -p {task_output_path}/{prefix}')\n",
    "    \n",
    "    # 1. sample ids of parallel tasks\n",
    "    # 将task specific样本列表作为one row添加到DataFrame中. 默认task是全部样本\n",
    "    cts = pd.read_csv(ctsfile, sep='\\t',index_col=0)\n",
    "    all_samples_df = pd.DataFrame(data=cts.columns.T.tolist()).transpose()\n",
    "    all_samples_df.index = task_config.index\n",
    "    all_samples_df.to_csv(f'{samples_path}/{prefix}.txt',sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304cc070",
   "metadata": {},
   "source": [
    "## subsampeling genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COL11A2', 'COL12A1', 'COL14A1', 'COL15A1', 'COL16A1', 'COL18A1', 'COL1A1', 'COL1A2', 'COL21A1', 'COL23A1', 'COL24A1', 'COL27A1', 'COL28A1', 'COL3A1', 'COL4A1', 'COL4A2', 'COL4A3', 'COL4A3BP', 'COL4A4', 'COL4A5', 'COL4A6', 'COL5A1', 'COL5A2', 'COL5A3', 'COL6A1', 'COL6A2', 'COL6A3', 'COL6A6', 'COL7A1', 'COL8A1', 'COL8A2', 'COLCA1', 'COLEC12', 'COLGALT1', 'COLGALT2', 'COLQ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_must_keep = [ g for g in cts.index if g.startswith('COL')]\n",
    "print(genes_must_keep ), len(genes_must_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_sizes = [ 12000 ]\n",
    "n_replicates = 10  # 每个样本量重复10次\n",
    "random_seeds = range(n_replicates)  # 使用0-9作为随机种子\n",
    "\n",
    "# 从tissues中获取信息\n",
    "for i, tissue_data in tissues.iterrows():\n",
    "    # tissue_data = tissues.iloc[0]\n",
    "    t = tissue_data['TISSUE_ID']  # TISSUE_ID\n",
    "    tn = tissue_data['TISSUE_NAME']  # TISSUE_NAME\n",
    "    ns = tissue_data['N_SAMPLE']  # N_SAMPLE\n",
    "    ng = tissue_data['N_GENE']  # N_GENE\n",
    "    ctsfile = tissue_data['CTS_FILE']  # CTS_FILE\n",
    "    outlierfile = tissue_data['OUTLIER_FILE']  # OUTLIER_FILE\n",
    "\n",
    "    # 创建基础前缀\n",
    "    base_prefix = f't{i:02d}_{t}_s{ns}_g{ng}' # id, number of samples, number of genes.\n",
    "    \n",
    "    cts = pd.read_csv(ctsfile, sep='\\t', index_col=0)\n",
    "    all_genes = cts.index.tolist()\n",
    "    all_samples = cts.columns.tolist()\n",
    "    print(i, t, tn, cts.shape, len(all_genes))\n",
    "    \n",
    "    genes_must_keep = [ g for g in cts.index if g.startswith('COL')]\n",
    "    print(genes_must_keep ), len(genes_must_keep)\n",
    "    # positive samples\n",
    "    # all negative samples\n",
    "    negative_genes = list(set(all_genes) - set(genes_must_keep) )\n",
    "    \n",
    "    # 创建字典存储所有抽样结果\n",
    "    sampled_configs = {}\n",
    "\n",
    "    # 对每个样本量进行抽样\n",
    "    for size in gene_sizes:\n",
    "        # 存储当前样本量的所有抽样结果\n",
    "        size_configs = {}\n",
    "        \n",
    "        for seed in random_seeds:\n",
    "            n_negative = size - len(genes_must_keep)\n",
    "            # 从阴性样本中随机抽样（数量 = 总样本量 - 阳性样本数量\n",
    "            negative_selected = pd.Series(negative_genes).sample(n = n_negative, random_state=seed).tolist() #, size=n_negative, replace=False)\n",
    "\n",
    "            # 合并阳性样本和随机选择的阴性样本\n",
    "            selected_genes =  genes_must_keep +  negative_selected\n",
    "            assert len(selected_genes) == len(set(selected_genes))\n",
    "            print(i,t, size, seed, len(selected_genes),  len(genes_must_keep), genes_must_keep[:3], n_negative, negative_selected[:3], )\n",
    "            \n",
    "            # new cts output. pmuscle_36 take subsets of genes\n",
    "            cts_selected = cts.loc[selected_genes].copy()\n",
    "            cts_selected_file = f'{ctsfile}.size{size}.seed{seed}.tsv.gz'\n",
    "            cts_selected.to_csv(cts_selected_file, sep='\\t')\n",
    "            \n",
    "            # 创建前缀\n",
    "            prefix = f'{base_prefix}_size{size}_seed{seed}'\n",
    "            \n",
    "            # 创建输出目录\n",
    "            output_dir = os.path.join(task_output_path, prefix)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # 创建样本列表文件\n",
    "            samples_file = os.path.join(samples_path, f'{prefix}.txt')\n",
    "            samples = pd.DataFrame(all_samples).transpose()\n",
    "            samples.index.name = 'task'\n",
    "            samples.to_csv(samples_file, sep='\\t', header=True)\n",
    "            \n",
    "            # 创建config文件\n",
    "            cols = ['Dname', 'cts', 'samples', 'MyMethod', 'OUTRIDER', 'ABEILLE', 'OUTSINGLE']\n",
    "            task_config = pd.DataFrame(columns=cols)\n",
    "            task_config.index.name = 'task'\n",
    "            # 填充config数据\n",
    "            task = 0\n",
    "            task_config.loc[0, 'Dname'] = t\n",
    "            task_config.loc[0, 'cts'] = cts_selected_file\n",
    "            task_config.loc[0, 'samples'] = samples_file\n",
    "            task_config.loc[0, 'MyMethod'] = os.path.join(output_dir, f'{task:03d}_mymethod.txt.gz')\n",
    "            task_config.loc[0, 'OUTRIDER'] = os.path.join(output_dir, f'{task:03d}_outrider.txt.gz')\n",
    "            task_config.loc[0, 'OUTSINGLE'] = os.path.join(output_dir, f'{task:03d}_outsingle.txt.gz')\n",
    "            task_config.loc[0, 'ABEILLE'] = os.path.join(output_dir, f'{task:03d}_abeille.txt.gz')\n",
    "            # {prefix}/{task:03d}\n",
    "            \n",
    "            # 保存config文件\n",
    "            config_file = os.path.join(task_config_path, f'{prefix}.config')\n",
    "            task_config.to_csv(config_file, sep='\\t', index=False)\n",
    "            \n",
    "            # 存储结果\n",
    "            size_configs[f'seed_{seed}'] = {\n",
    "                'config': task_config,\n",
    "                'selected_genes': selected_genes,\n",
    "                'selected_samples': all_samples,\n",
    "                'output_dir': output_dir\n",
    "            }\n",
    "        \n",
    "        # 将当前样本量的所有结果存入总字典\n",
    "        sampled_configs[f'size_{size}'] = size_configs\n",
    "\n",
    "    # sampled_configs现在包含了所有抽样结果和对应的配置文件\n",
    "    # 结构为：{sample_size: {seed: {'config': df, 'selected_genes': list, 'output_dir': str}}, ...}\n",
    "    output_file = os.path.join(task_config_path, f'{base_prefix}_sampled_configs_dict.pkl')\n",
    "    # 保存sampled_configs字典\n",
    "    import pickle\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(sampled_configs, f)\n",
    "\n",
    "    print(f\"sampled_configs已保存到: {output_file}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8648a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.12]",
   "language": "python",
   "name": "conda-env-py3.12-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
